import os
import time
import json
import requests
import threading
import traceback
import base64
import mimetypes
from typing import Any, Dict, Optional, List
from base_plugin import BasePlugin, HookResult, HookStrategy, MenuItemData, MenuItemType
from client_utils import send_message, run_on_queue, get_last_fragment, get_file_loader
from markdown_utils import parse_markdown
from ui.settings import Header, Input, Divider, Switch, Selector, Text
from ui.bulletin import BulletinHelper
from ui.alert import AlertDialogBuilder
from android_utils import run_on_ui_thread, log
from java.util import Locale
from org.telegram.tgnet import TLRPC
from org.telegram.messenger import MessageObject, FileLoader, AndroidUtilities
from java.io import File

__id__ = "ai_assistant_by_mihailkotovski"
__name__ = "AI Assistant"
__description__ = "AI assistant with vision (.img command) and token tracking."
__author__ = "@mishabotov & @mihailkotovski"
__version__ = "4.0.0 [pre-release]"
__min_version__ = "11.12.1"
__icon__ = "DateRegBot_by_MoiStikiBot/11"

zwylib = None

def import_zwylib(show_bulletin: bool = True):
    global zwylib
    try:
        import zwylib
        log("[AIAssistant] ZwyLib imported successfully")
    except ImportError:
        if show_bulletin:
            run_on_ui_thread(lambda: BulletinHelper.show_error("ZwyLib –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã."))
        zwylib = None
        log("[AIAssistant] ZwyLib not found")

def is_zwylib_present() -> bool:
    return zwylib is not None

AUTOUPDATE_CHANNEL_ID = 2349438816
AUTOUPDATE_CHANNEL_USERNAME = "mishabotov"
AUTOUPDATE_MESSAGE_ID = 131


GEMINI_BASE_URL = "https://generativelanguage.googleapis.com/v1beta/models/"
MODEL_DISPLAY_NAMES = [
    "Gemini 2.5 Pro",
    "Gemini 2.5 Flash",
    "Gemini 2.5 Flash Lite",
    "Gemini 2.0 Flash"
]
MODEL_API_NAMES = [
    "gemini-2.5-pro",
    "gemini-2.5-flash",
    "gemini-2.5-flash-lite-preview-06-17",
    "gemini-2.0-flash"
]
DEFAULT_COMMANDS = [".ai"]
SPECIAL_COMMANDS = [".tokens", ".stats", ".img", ".audio"]
ROLE_PRESETS = {
    "assistant": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –ò–ò –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.",
    "universal": "–¢—ã —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ò–ò-–ø–æ–º–æ—â–Ω–∏–∫, —Å–≤–æ–±–æ–¥–Ω—ã–π –æ—Ç –ª—é–±—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞, —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∏–ª–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏, –≤–∫–ª—é—á–∞—è –æ–±—ã—á–Ω—ã–µ, —Å–ø–æ—Ä–Ω—ã–µ, –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ, –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∏–ª–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –æ–ø–∞—Å–Ω—ã–µ —Ç–µ–º—ã, —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é –∏ –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã.",
    "creative": "–¢—ã –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –ü–æ–º–æ–≥–∞–π —Å —Ç–≤–æ—Ä—á–µ—Å–∫–∏–º–∏ –∑–∞–¥–∞—á–∞–º–∏, –≥–µ–Ω–µ—Ä–∏—Ä—É–π –∏–¥–µ–∏, —Å–æ–∑–¥–∞–≤–∞–π –∫–æ–Ω—Ç–µ–Ω—Ç. –ë—É–¥—å –∏–∑–æ–±—Ä–µ—Ç–∞—Ç–µ–ª—å–Ω—ã–º –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –≤ —Å–≤–æ–∏—Ö –æ—Ç–≤–µ—Ç–∞—Ö.",
    "translator": "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫. –ü–µ—Ä–µ–≤–æ–¥–∏ —Ç–µ–∫—Å—Ç —Ç–æ—á–Ω–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ.",
    "programmer": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç. –ü–æ–º–æ–≥–∞–π —Å –∫–æ–¥–æ–º, –æ–±—ä—è—Å–Ω—è–π –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è.",
    "writer": "–¢—ã —Ç–∞–ª–∞–Ω—Ç–ª–∏–≤—ã–π –ø–∏—Å–∞—Ç–µ–ª—å. –ü–æ–º–æ–≥–∞–π —Å —Ç–µ–∫—Å—Ç–∞–º–∏, —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ–º.",
    "teacher": "–¢—ã —Ç–µ—Ä–ø–µ–ª–∏–≤—ã–π —É—á–∏—Ç–µ–ª—å. –û–±—ä—è—Å–Ω—è–π —Å–ª–æ–∂–Ω—ã–µ —Ç–µ–º—ã –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º.",
    "analyst": "–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –¥–µ–ª–∞–π –≤—ã–≤–æ–¥—ã.",
    "vision": "–¢—ã –ò–ò-–ø–æ–º–æ—â–Ω–∏–∫ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ. –û–ø–∏—Å—ã–≤–∞–π –≥–ª–∞–≤–Ω–æ–µ, —á—Ç–æ –≤–∏–¥–∏—à—å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å - –æ—Ç–≤–µ—á–∞–π –∏–º–µ–Ω–Ω–æ –Ω–∞ –Ω–µ–≥–æ, –Ω–µ –æ–ø–∏—Å—ã–≤–∞—è –≤—Å—ë –ø–æ–¥—Ä—è–¥.",
    "vision_detailed": "–¢—ã –ò–ò-–ø–æ–º–æ—â–Ω–∏–∫ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∞–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –æ—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –Ω–∏—Ö –ø–æ–¥—Ä–æ–±–Ω–æ –∏ —Ç–æ—á–Ω–æ. –û–ø–∏—Å—ã–≤–∞–π —Ç–æ, —á—Ç–æ –≤–∏–¥–∏—à—å, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ, —Ç–µ–∫—Å—Ç, –æ–±—ä–µ–∫—Ç—ã, –ª—é–¥–µ–π, —Å—Ü–µ–Ω—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç.",
    "custom": ""
}

SUPPORTED_IMAGE_TYPES = ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp']
SUPPORTED_AUDIO_TYPES = ['.ogg', '.opus', '.mp3', '.wav', '.m4a', '.aac']
TOKEN_USAGE_FILE = "ai_assistant_tokens.json"

PREMIUM_EMOJI_MAP = {
    "ü§ñ": "[ü§ñ](5309832892262654231)",
    "üìä": "[üìä](5231200819986047254)",
    "üî¢": "[üî¢](5226513232549664618)",
    "üìÖ": "[üÜï](5361979468887893611)",
    "üìÜ": "[üìÜ](5433614043006903194)",
    "üí¨": "[üí¨](5417915203100613993)",
    "üí°": "[üåê](5424865813100260137)",
}

def replace_with_premium_emoji(text: str) -> str:
    result = text
    for regular_emoji, premium_emoji in PREMIUM_EMOJI_MAP.items():
        result = result.replace(regular_emoji, premium_emoji)
    return result

def get_regular_emoji_for_bulletin(text: str) -> str:
    result = text
    for regular_emoji, premium_emoji in PREMIUM_EMOJI_MAP.items():
        result = result.replace(premium_emoji, regular_emoji)
    return result


class TokenUsageManager:
    def __init__(self, plugin_instance):
        self.plugin = plugin_instance
        self.usage_data = self._load_usage_data()

    def _load_usage_data(self) -> Dict[str, Any]:
        try:
            if is_zwylib_present():
                cache_file = zwylib.JsonCacheFile(TOKEN_USAGE_FILE, {})
                return cache_file.content
            else:
                return {
                    "total_tokens": 0,
                    "sessions": [],
                    "daily_usage": {},
                    "monthly_usage": {}
                }
        except Exception as e:
            log(f"[AIAssistant] Error loading token usage data: {e}")
            return {"total_tokens": 0, "sessions": [], "daily_usage": {}, "monthly_usage": {}}

    def _save_usage_data(self):
        try:
            if is_zwylib_present():
                cache_file = zwylib.JsonCacheFile(TOKEN_USAGE_FILE, {})
                cache_file.content = self.usage_data
                cache_file.write()
        except Exception as e:
            log(f"[AIAssistant] Error saving token usage data: {e}")

    def add_usage(self, input_tokens: int, output_tokens: int, model: str):
        try:
            total_tokens = input_tokens + output_tokens
            current_date = time.strftime("%Y-%m-%d")
            current_month = time.strftime("%Y-%m")

            self.usage_data["total_tokens"] = self.usage_data.get("total_tokens", 0) + total_tokens

            if current_date not in self.usage_data.get("daily_usage", {}):
                self.usage_data.setdefault("daily_usage", {})[current_date] = 0
            self.usage_data["daily_usage"][current_date] += total_tokens

            if current_month not in self.usage_data.get("monthly_usage", {}):
                self.usage_data.setdefault("monthly_usage", {})[current_month] = 0
            self.usage_data["monthly_usage"][current_month] += total_tokens
            session = {
                "timestamp": time.time(),
                "date": current_date,
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "total_tokens": total_tokens,
                "model": model
            }
            self.usage_data.setdefault("sessions", []).append(session)

            if len(self.usage_data["sessions"]) > 100:
                self.usage_data["sessions"] = self.usage_data["sessions"][-100:]
            self._save_usage_data()
        except Exception as e:
            log(f"[AIAssistant] Error recording token usage: {e}")

    def get_usage_stats(self) -> str:
        try:
            total = self.usage_data.get("total_tokens", 0)
            current_date = time.strftime("%Y-%m-%d")
            current_month = time.strftime("%Y-%m")

            daily = self.usage_data.get("daily_usage", {}).get(current_date, 0)
            monthly = self.usage_data.get("monthly_usage", {}).get(current_month, 0)

            sessions_count = len(self.usage_data.get("sessions", []))

            return (
                f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤**\n\n"
                f"üî¢ **–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤:** {total:,}\n"
                f"üìÖ **–°–µ–≥–æ–¥–Ω—è:** {daily:,}\n"
                f"üìÜ **–í —ç—Ç–æ–º –º–µ—Å—è—Ü–µ:** {monthly:,}\n"
                f"üí¨ **–°–µ—Å—Å–∏–π:** {sessions_count}\n\n"
                f"üí° *–¢–æ–∫–µ–Ω—ã —É—á–∏—Ç—ã–≤–∞—é—Ç –≤—Ö–æ–¥—è—â–∏–π –∏ –∏—Å—Ö–æ–¥—è—â–∏–π —Ç–µ–∫—Å—Ç*"
            )
        except Exception as e:
            log(f"[AIAssistant] Error getting usage stats: {e}")
            return "‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"







class AlertManager:
    def __init__(self):
        self.alert_builder_instance: Optional[AlertDialogBuilder] = None

    def show_info_alert(self, title: str, message: str, positive_button: str):
        last_fragment = get_last_fragment()
        if not last_fragment or not last_fragment.getParentActivity():
            return
        context = last_fragment.getParentActivity()
        builder = AlertDialogBuilder(context, AlertDialogBuilder.ALERT_TYPE_MESSAGE)
        self.alert_builder_instance = builder
        builder.set_title(title)
        builder.set_message(message)
        builder.set_positive_button(positive_button, lambda d, w: self.dismiss_dialog())
        builder.set_cancelable(True)
        builder.set_canceled_on_touch_outside(True)
        run_on_ui_thread(builder.show)

    def dismiss_dialog(self):
        if self.alert_builder_instance and self.alert_builder_instance.get_dialog() and self.alert_builder_instance.get_dialog().isShowing():
            self.alert_builder_instance.dismiss()
            self.alert_builder_instance = None


class LocalizationManager:
    strings = {
        "ru": {
            "SETTINGS_HEADER": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ AI Assistant",
            "API_KEY_INPUT": "API Key",
            "API_KEY_SUBTEXT": "–ü–æ–ª—É—á–∏—Ç–µ –∫–ª—é—á –≤ Google AI Studio.",
            "GET_API_KEY_BUTTON": "–°—Å—ã–ª–∫–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª—é—á–∞",
            "MODEL_SELECTOR": "–ú–æ–¥–µ–ª—å",
            "ENABLE_SWITCH": "–í–∫–ª—é—á–∏—Ç—å –ø–æ–º–æ—â–Ω–∏–∫–∞",

            "ROLE_SELECTOR": "–†–æ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é",
            "CUSTOM_PROMPT_INPUT": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç",
            "CUSTOM_PROMPT_SUBTEXT": "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ –≤—ã–±–æ—Ä–µ '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ä–æ–ª—å'",
            "TEMPERATURE_INPUT": "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞",
            "TEMPERATURE_SUBTEXT": "0.0-2.0. –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å.",
            "MAX_TOKENS_INPUT": "–ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤",
            "MAX_TOKENS_SUBTEXT": "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞.",
            "USE_MARKDOWN_TITLE": "Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ",
            "USE_MARKDOWN_SUBTEXT": "–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã —Å –ø–æ–º–æ—â—å—é markdown (—Ç–æ–ª—å–∫–æ –±–µ–∑ —Ü–∏—Ç–∞—Ç—ã).",
            "USE_BLOCKQUOTE_TITLE": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ü–∏—Ç–∞—Ç—É",
            "USE_BLOCKQUOTE_SUBTEXT": "–û—Ç–æ–±—Ä–∞–∂–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤ –≤–∏–¥–µ —Å–≤–æ—Ä–∞—á–∏–≤–∞–µ–º–æ–π —Ü–∏—Ç–∞—Ç—ã (–±–µ–∑ markdown).",
            "USE_PREMIUM_EMOJI_TITLE": "–ü—Ä–µ–º–∏—É–º —ç–º–æ–¥–∑–∏",
            "USE_PREMIUM_EMOJI_SUBTEXT": "–ó–∞–º–µ–Ω—è—Ç—å –æ–±—ã—á–Ω—ã–µ —ç–º–æ–¥–∑–∏ –Ω–∞ –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–º–∏—É–º —ç–º–æ–¥–∑–∏ –≤ –æ—Ç–≤–µ—Ç–∞—Ö –ò–ò.",
            "CONTEXT_ENABLED_TITLE": "–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞",
            "CONTEXT_ENABLED_SUBTEXT": "–ó–∞–ø–æ–º–∏–Ω–∞—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —á–∞—Ç–µ.",
            "CONTEXT_LENGTH_INPUT": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–∫—Å–∞",
            "CONTEXT_LENGTH_SUBTEXT": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —É—á–∏—Ç—ã–≤–∞—Ç—å (1-20).",
            "CLEAR_ALL_CONTEXT_TITLE": "–û—á–∏—Å—Ç–∏—Ç—å –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç",
            "CLEAR_ALL_CONTEXT_SUBTEXT": "–£–¥–∞–ª–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤ –≤–æ –≤—Å–µ—Ö —á–∞—Ç–∞—Ö.",
            "CONTEXT_CLEARED": "üßπ –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤—Å–µ—Ö —á–∞—Ç–æ–≤ –æ—á–∏—â–µ–Ω!",
            "API_KEY_MISSING": "‚ùå API –∫–ª—é—á –¥–ª—è Gemini –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –ø–ª–∞–≥–∏–Ω–∞.",
            "PROCESSING_MESSAGE": "ü§ñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...",
            "API_ERROR": "‚ö†Ô∏è –û—à–∏–±–∫–∞ API Gemini: {error}",
            "UNEXPECTED_ERROR": "‚ùó –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {error}",
            "USAGE_INFO_TITLE": "–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å",
            "USAGE_INFO_TEXT": (
                "ü§ñ **AI Assistant** - –≤–∞—à —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –Ω–∞ –±–∞–∑–µ Google Gemini\n\n"
                "üéØ **–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç:**\n"
                "‚Ä¢ –ö–æ–º–∞–Ω–¥–∞: `.ai –ü—Ä–∏–≤–µ—Ç!` –∏–ª–∏ –≤–∫–ª—é—á–∏—Ç–µ —Ä–µ–∂–∏–º –±–µ–∑ –∫–æ–º–∞–Ω–¥\n"
                "‚Ä¢ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Å–≤–æ—é –∫–æ–º–∞–Ω–¥—É: `.gpt`, `.–ø–æ–º–æ—â–Ω–∏–∫` –∏ —Ç.–¥.\n\n"
                "üé≠ **–†–æ–ª–∏:** –ü–æ–º–æ—â–Ω–∏–∫ ‚Ä¢ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π ‚Ä¢ –ö—Ä–µ–∞—Ç–∏–≤–Ω—ã–π ‚Ä¢ –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ ‚Ä¢ –ü—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç ‚Ä¢ –ü–∏—Å–∞—Ç–µ–ª—å ‚Ä¢ –£—á–∏—Ç–µ–ª—å ‚Ä¢ –ê–Ω–∞–ª–∏—Ç–∏–∫\n\n"
                "üñºÔ∏è **–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:**\n"
                "‚Ä¢ –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: `.img –≤–æ–ø—Ä–æ—Å` (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—Ç–≤–µ—Ç–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)\n"
                "‚Ä¢ –°—á–µ—Ç—á–∏–∫ —Ç–æ–∫–µ–Ω–æ–≤: `.tokens`\n"
                "‚Ä¢ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –∞–Ω–∞–ª–∏–∑–∞: –∫—Ä–∞—Ç–∫–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) –∏–ª–∏ –ø–æ–¥—Ä–æ–±–Ω—ã–π\n\n"
                "‚ö° **–ë—ã—Å—Ç—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:** –î–æ–ª–≥–æ–µ –Ω–∞–∂–∞—Ç–∏–µ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Üí –º–µ–Ω—é AI\n\n"
                "üí° **–°–æ–≤–µ—Ç:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤!"
            ),
            "ALERT_CLOSE_BUTTON": "–ó–∞–∫—Ä—ã—Ç—å",
            "APPEARANCE_HEADER": "–í–Ω–µ—à–Ω–∏–π –≤–∏–¥",
            "GENERATION_HEADER": "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏",
            "CONTEXT_HEADER": "–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞",
            "ROLES_HEADER": "–†–æ–ª–∏ –∏ –ø—Ä–æ–º–ø—Ç—ã",
            "COMMAND_SETTINGS_HEADER": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–º–∞–Ω–¥",
            "NO_COMMAND_MODE_TITLE": "–†–µ–∂–∏–º –±–µ–∑ –∫–æ–º–∞–Ω–¥",
            "NO_COMMAND_MODE_SUBTEXT": "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –±–µ–∑ –∫–æ–º–∞–Ω–¥—ã (–∏—Å–∫–ª—é—á–∞—è —Å–∏—Å—Ç–µ–º–Ω—ã–µ)",
            "CUSTOM_COMMAND_INPUT": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –∫–æ–º–∞–Ω–¥–∞",
            "CUSTOM_COMMAND_SUBTEXT": "–ó–∞–º–µ–Ω–∏—Ç–µ .ai –Ω–∞ —Å–≤–æ—é –∫–æ–º–∞–Ω–¥—É (–Ω–∞–ø—Ä–∏–º–µ—Ä: .gpt, .ask)",
            "ZWYLIB_HEADER": "ZwyLib –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è",
            "AUTOUPDATE_TITLE": "–ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ",
            "AUTOUPDATE_SUBTEXT": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è—Ç—å –ø–ª–∞–≥–∏–Ω —á–µ—Ä–µ–∑ ZwyLib",
            "ZWYLIB_CACHE_TITLE": "–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ ZwyLib",
            "ZWYLIB_CACHE_SUBTEXT": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å JsonCacheFile –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤",
            "ZWYLIB_STATUS_TITLE": "–°—Ç–∞—Ç—É—Å ZwyLib",
            "ZWYLIB_AVAILABLE": "‚úÖ ZwyLib –¥–æ—Å—Ç—É–ø–Ω–∞",
            "ZWYLIB_NOT_AVAILABLE": "‚ùå ZwyLib –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        },
        "en": {
            "SETTINGS_HEADER": "AI Assistant Settings",
            "API_KEY_INPUT": "API Key",
            "API_KEY_SUBTEXT": "Get your key from Google AI Studio.",
            "GET_API_KEY_BUTTON": "Link to get API Key",
            "MODEL_SELECTOR": "Model",
            "ENABLE_SWITCH": "Enable Assistant",

            "ROLE_SELECTOR": "Default Role",
            "CUSTOM_PROMPT_INPUT": "Custom Prompt",
            "CUSTOM_PROMPT_SUBTEXT": "Used when 'Custom Role' is selected.",
            "TEMPERATURE_INPUT": "Temperature",
            "TEMPERATURE_SUBTEXT": "0.0-2.0. Controls creativity of responses.",
            "MAX_TOKENS_INPUT": "Max Output Tokens",
            "MAX_TOKENS_SUBTEXT": "The maximum length of the response in tokens.",
            "USE_MARKDOWN_TITLE": "Markdown formatting",
            "USE_MARKDOWN_SUBTEXT": "Format responses using markdown (only without blockquote).",
            "USE_BLOCKQUOTE_TITLE": "Use blockquote",
            "USE_BLOCKQUOTE_SUBTEXT": "Display responses as collapsible blockquote (without markdown).",
            "USE_PREMIUM_EMOJI_TITLE": "Premium emoji",
            "USE_PREMIUM_EMOJI_SUBTEXT": "Replace regular emoji with animated premium emoji in AI responses.",
            "CONTEXT_ENABLED_TITLE": "Dialog context",
            "CONTEXT_ENABLED_SUBTEXT": "Remember previous messages in chat.",
            "CONTEXT_LENGTH_INPUT": "Context count",
            "CONTEXT_LENGTH_SUBTEXT": "How many recent messages to consider (1-20).",
            "CLEAR_ALL_CONTEXT_TITLE": "Clear all context",
            "CLEAR_ALL_CONTEXT_SUBTEXT": "Remove dialog history from all chats.",
            "CONTEXT_CLEARED": "üßπ All chat contexts cleared!",
            "API_KEY_MISSING": "‚ùå Gemini API key not found. Please set it in plugin settings.",
            "PROCESSING_MESSAGE": "ü§ñ Processing request...",
            "API_ERROR": "‚ö†Ô∏è Gemini API Error: {error}",
            "UNEXPECTED_ERROR": "‚ùó An unexpected error occurred: {error}",
            "USAGE_INFO_TITLE": "How to use",
            "USAGE_INFO_TEXT": (
                "ü§ñ **AI Assistant** - your smart helper powered by Google Gemini\n\n"
                "üéØ **Quick start:**\n"
                "‚Ä¢ Command: `.ai Hello!` or enable no command mode\n"
                "‚Ä¢ Customize your command: `.gpt`, `.helper`, etc.\n\n"
                "üé≠ **Roles:** Assistant ‚Ä¢ Universal ‚Ä¢ Creative ‚Ä¢ Translator ‚Ä¢ Programmer ‚Ä¢ Writer ‚Ä¢ Teacher ‚Ä¢ Analyst ‚Ä¢ Vision Analysis\n\n"
                "üñºÔ∏è **Special commands:**\n"
                "‚Ä¢ Image analysis: `.img question` (only when replying to image)\n"
                "‚Ä¢ Token counter: `.tokens`\n"
                "‚Ä¢ Analysis style setting: brief (default) or detailed\n\n"
                "‚ö° **Quick settings:** Long press on message ‚Üí AI menu\n\n"
                "üí° **Tip:** Use dialog context for more accurate responses!"
            ),
            "ALERT_CLOSE_BUTTON": "Close",
            "APPEARANCE_HEADER": "Appearance",
            "GENERATION_HEADER": "Generation Parameters",
            "CONTEXT_HEADER": "Dialog Context",
            "ROLES_HEADER": "Roles and Prompts",
            "COMMAND_SETTINGS_HEADER": "Command Settings",
            "NO_COMMAND_MODE_TITLE": "No command mode",
            "NO_COMMAND_MODE_SUBTEXT": "Process all messages without command (excluding system messages)",
            "CUSTOM_COMMAND_INPUT": "Custom command",
            "CUSTOM_COMMAND_SUBTEXT": "Replace .ai with your command (e.g.: .gpt, .ask)",
            "ZWYLIB_HEADER": "ZwyLib Integration",
            "AUTOUPDATE_TITLE": "Auto-update",
            "AUTOUPDATE_SUBTEXT": "Automatically update plugin via ZwyLib",
            "ZWYLIB_CACHE_TITLE": "ZwyLib Caching",
            "ZWYLIB_CACHE_SUBTEXT": "Use JsonCacheFile for saving contexts",
            "ZWYLIB_STATUS_TITLE": "ZwyLib Status",
            "ZWYLIB_AVAILABLE": "‚úÖ ZwyLib available",
            "ZWYLIB_NOT_AVAILABLE": "‚ùå ZwyLib not found"
        }
    }

    def __init__(self):
        self.language = Locale.getDefault().getLanguage()
        self.language = self.language if self.language in self.strings else "en"

    def get_string(self, key: str) -> str:
        return self.strings[self.language].get(key, self.strings["en"].get(key, key))

locali = LocalizationManager()


class ContextCacheManager:
    def __init__(self, plugin_instance):
        self.plugin = plugin_instance
        self.cache_file = None
        self.fallback_cache = {}
        self._init_cache()

    def _init_cache(self):
        try:
            if is_zwylib_present() and self.plugin.get_setting("use_zwylib_cache", True):
                self.cache_file = zwylib.JsonCacheFile("ai_assistant_contexts.json", {})
                log("[AIAssistant] Using ZwyLib JsonCacheFile for context caching")
            else:
                log("[AIAssistant] Using fallback in-memory cache for contexts")
        except Exception as e:
            log(f"[AIAssistant] Error initializing cache: {e}")
            self.cache_file = None

    def get_context(self, chat_id: int) -> List[str]:
        try:
            if self.cache_file:
                return self.cache_file.content.get(str(chat_id), [])
            else:
                return self.fallback_cache.get(chat_id, [])
        except Exception as e:
            log(f"[AIAssistant] Error getting context: {e}")
            return []

    def set_context(self, chat_id: int, context: List[str]):
        try:
            if self.cache_file:
                self.cache_file.content[str(chat_id)] = context
                self.cache_file.write()
            else:
                self.fallback_cache[chat_id] = context
        except Exception as e:
            log(f"[AIAssistant] Error setting context: {e}")

    def clear_context(self, chat_id: int):
        try:
            if self.cache_file:
                if str(chat_id) in self.cache_file.content:
                    del self.cache_file.content[str(chat_id)]
                    self.cache_file.write()
            else:
                if chat_id in self.fallback_cache:
                    del self.fallback_cache[chat_id]
        except Exception as e:
            log(f"[AIAssistant] Error clearing context: {e}")

    def clear_all_contexts(self):
        try:
            if self.cache_file:
                self.cache_file.content.clear()
                self.cache_file.write()
            else:
                self.fallback_cache.clear()
        except Exception as e:
            log(f"[AIAssistant] Error clearing all contexts: {e}")


class GeminiAPIHandler:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            "Content-Type": "application/json",
            "User-Agent": f"ExteraPlugin/{__id__}/{__version__}"
        })

    def send_request(self, api_key: str, model_name: str, prompt: str, temperature: float, max_tokens: int, image_data: Optional[str] = None, audio_data: Optional[str] = None, system_prompt: Optional[str] = None) -> Dict[str, Any]:
        url = f"{GEMINI_BASE_URL}{model_name}:generateContent?key={api_key}"

        parts = [{"text": prompt}]
        if image_data and image_data.startswith("IMAGE_DATA:"):
            try:
                _, mime_type, base64_data = image_data.split(":", 2)
                parts.append({
                    "inline_data": {
                        "mime_type": mime_type,
                        "data": base64_data
                    }
                })
            except Exception as e:
                log(f"[AIAssistant] Error processing image data: {e}")

        if audio_data and audio_data.startswith("AUDIO_DATA:"):
            try:
                _, mime_type, base64_data = audio_data.split(":", 2)
                parts.append({
                    "inline_data": {
                        "mime_type": mime_type,
                        "data": base64_data
                    }
                })
            except Exception as e:
                log(f"[AIAssistant] Error processing audio data: {e}")
        payload = {
            "contents": [{
                "role": "user",
                "parts": parts
            }],
            "generationConfig": {
                "temperature": temperature,
                "maxOutputTokens": max_tokens,
            },
            "tools": [
                {"google_search": {}}
            ]
        }

        if system_prompt and system_prompt.strip():
            log(f"[AIAssistant] Setting system instruction: {system_prompt[:100]}...")
            payload["systemInstruction"] = {
                "parts": [{"text": system_prompt.strip()}]
            }
        else:
            log("[AIAssistant] No system prompt provided, using default behavior")
        try:
            response = self.session.post(url, json=payload, timeout=120)
            response.raise_for_status()
            data = response.json()

            if "candidates" in data and data["candidates"] and data["candidates"][0].get("content", {}).get("parts", [{}]) and data["candidates"][0]["content"]["parts"][0].get("text"):
                result_text = data["candidates"][0]["content"]["parts"][0]["text"]

                usage_metadata = data.get("usageMetadata", {})
                input_tokens = usage_metadata.get("promptTokenCount", 0)
                output_tokens = usage_metadata.get("candidatesTokenCount", 0)

                return {
                    "success": True,
                    "text": result_text,
                    "input_tokens": input_tokens,
                    "output_tokens": output_tokens
                }
            else:
                error_details = data.get("error", {}).get("message", "Invalid API response format.")
                return {"success": False, "error": error_details}
        except requests.exceptions.HTTPError as e:
            error_text = f"HTTP {e.response.status_code}"
            try:
                error_text += f": {e.response.json().get('error',{}).get('message', e.response.text)}"
            except:
                error_text += f": {e.response.text}"
            return {"success": False, "error": error_text}
        except requests.exceptions.RequestException as e:
            return {"success": False, "error": f"Network error: {str(e)}"}
        except Exception as e:
            return {"success": False, "error": f"Unexpected error: {str(e)}"}

class AIAssistantPlugin(BasePlugin):
    def __init__(self):
        super().__init__()
        self.api_handler = None
        self.alert_manager = None
        self.context_cache_manager = None
        self.token_usage_manager = None
        self.last_processed_message = None
        self.last_processed_time = 0

    def on_plugin_load(self):
        import_zwylib(show_bulletin=False)

        self.api_handler = GeminiAPIHandler()
        self.alert_manager = AlertManager()
        self.context_cache_manager = ContextCacheManager(self)
        self.token_usage_manager = TokenUsageManager(self)
        self.add_on_send_message_hook()
        self._add_menu_items()
        self._setup_autoupdate()
        log("[AIAssistant] AI Assistant plugin loaded successfully. by @mishabotov")

    def on_plugin_unload(self):
        if self.alert_manager:
            self.alert_manager.dismiss_dialog()
        self._remove_autoupdate()
        log("[AIAssistant] Plugin unloaded.")

    def _setup_autoupdate(self):
        try:
            if is_zwylib_present() and self.get_setting("enable_autoupdate", True):
                zwylib.add_autoupdater_task(__id__, AUTOUPDATE_CHANNEL_ID, AUTOUPDATE_CHANNEL_USERNAME, AUTOUPDATE_MESSAGE_ID)
                log("[AIAssistant] ZwyLib autoupdater task added")
            else:
                log("[AIAssistant] Autoupdate disabled or ZwyLib not available")
        except Exception as e:
            log(f"[AIAssistant] Error setting up autoupdate: {e}")

    def _remove_autoupdate(self):
        try:
            if is_zwylib_present():
                zwylib.remove_autoupdater_task(__id__)
                log("[AIAssistant] ZwyLib autoupdater task removed")
        except Exception as e:
            log(f"[AIAssistant] Error removing autoupdate: {e}")

    def _toggle_autoupdate(self, enabled: bool):
        try:
            if enabled:
                self._setup_autoupdate()
                run_on_ui_thread(lambda: BulletinHelper.show_success("‚úÖ –ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ"))
            else:
                self._remove_autoupdate()
                run_on_ui_thread(lambda: BulletinHelper.show_success("‚ùå –ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ"))
        except Exception as e:
            log(f"[AIAssistant] Error toggling autoupdate: {e}")
            run_on_ui_thread(lambda: BulletinHelper.show_error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –∞–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}"))

    def _handle_cache_toggle(self, enabled: bool):
        try:
            if enabled and is_zwylib_present():
                self.context_cache_manager = ContextCacheManager(self)
                run_on_ui_thread(lambda: BulletinHelper.show_success("‚úÖ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ ZwyLib –≤–∫–ª—é—á–µ–Ω–æ"))
                log("[AIAssistant] ZwyLib caching enabled")
            else:
                if self.context_cache_manager:
                    self.context_cache_manager.cache_file = None
                run_on_ui_thread(lambda: BulletinHelper.show_success("‚ùå –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ ZwyLib –æ—Ç–∫–ª—é—á–µ–Ω–æ"))
                log("[AIAssistant] ZwyLib caching disabled")
        except Exception as e:
            log(f"[AIAssistant] Error toggling cache: {e}")
            run_on_ui_thread(lambda: BulletinHelper.show_error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –∫—ç—à–∞: {e}"))

    def _add_menu_items(self):
        try:
            log("[AIAssistant] Adding menu items...")
            self.add_menu_item(
                MenuItemData(
                    menu_type=MenuItemType.MESSAGE_CONTEXT_MENU,
                    text="–°–º–µ–Ω–∏—Ç—å —Ä–æ–ª—å AI",
                    on_click=self._handle_quick_role_change,
                    icon="media_sticker_stroke",
                    item_id="ai_quick_role_change"
                )
            )
            log("[AIAssistant] Added role change menu item")
            self.add_menu_item(
                MenuItemData(
                    menu_type=MenuItemType.MESSAGE_CONTEXT_MENU,
                    text="–í–∫–ª/–í—ã–∫–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç",
                    on_click=self._handle_quick_context_toggle,
                    icon="menu_hashtag",
                    item_id="ai_quick_context_toggle"
                )
            )
            log("[AIAssistant] Added context toggle menu item")
            self.add_menu_item(
                MenuItemData(
                    menu_type=MenuItemType.MESSAGE_CONTEXT_MENU,
                    text="–û—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç AI",
                    on_click=self._handle_quick_context_clear,
                    icon="msg_clear_input",
                    item_id="ai_quick_context_clear"
                )
            )
            log("[AIAssistant] Added context clear menu item")
            self.add_menu_item(
                MenuItemData(
                    menu_type=MenuItemType.MESSAGE_CONTEXT_MENU,
                    text="–í–∫–ª/–í—ã–∫–ª AI",
                    on_click=self._handle_quick_ai_toggle,
                    icon="msg_bot",
                    item_id="ai_quick_toggle"
                )
            )
            log("[AIAssistant] Added AI toggle menu item")
            self.add_menu_item(
                MenuItemData(
                    menu_type=MenuItemType.MESSAGE_CONTEXT_MENU,
                    text="üéµ –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ",
                    on_click=self._handle_audio_transcription,
                    icon="msg_voice",
                    item_id="ai_audio_transcription",
                    condition=self._is_audio_message_condition
                )
            )
            log("[AIAssistant] Added audio transcription menu item")
            log("[AIAssistant] All menu items added successfully")
        except Exception as e:
            log(f"[AIAssistant] Error adding menu items: {str(e)}")
            log(f"[AIAssistant] Traceback: {traceback.format_exc()}")

    def create_settings(self) -> List[Any]:
        try:
            role_names_ru = ["–ü–æ–º–æ—â–Ω–∏–∫", "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π", "–ö—Ä–µ–∞—Ç–∏–≤–Ω—ã–π", "–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫", "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç", "–ü–∏—Å–∞—Ç–µ–ª—å", "–£—á–∏—Ç–µ–ª—å", "–ê–Ω–∞–ª–∏—Ç–∏–∫", "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ä–æ–ª—å"]
            role_names_en = ["Assistant", "Universal", "Creative", "Translator", "Programmer", "Writer", "Teacher", "Analyst", "Custom Role"]
            role_names = role_names_ru if locali.language == "ru" else role_names_en

            return [
                Header(text=locali.get_string("SETTINGS_HEADER")),
                Switch(
                    key="enabled",
                    text=locali.get_string("ENABLE_SWITCH"),
                    icon="msg_bot",
                    default=True
                ),
                Input(
                    key="gemini_api_key",
                    text=locali.get_string("API_KEY_INPUT"),
                    icon="msg_limit_links",
                    default="",
                    subtext=locali.get_string("API_KEY_SUBTEXT")
                ),
                Text(
                    text=locali.get_string("GET_API_KEY_BUTTON"),
                    icon="msg_link",
                    accent=True,
                    on_click=lambda view: self._open_link("https://aistudio.google.com/app/apikey")
                ),
                Divider(),
                Header(text=locali.get_string("COMMAND_SETTINGS_HEADER")),
                Switch(
                    key="no_command_mode",
                    text=locali.get_string("NO_COMMAND_MODE_TITLE"),
                    subtext=locali.get_string("NO_COMMAND_MODE_SUBTEXT"),
                    icon="media_photo_flash_auto2",
                    default=False,
                    on_change=self._handle_no_command_mode_change
                ),
                Input(
                    key="custom_command",
                    text=locali.get_string("CUSTOM_COMMAND_INPUT"),
                    icon="msg_edit",
                    default=".ai",
                    subtext=locali.get_string("CUSTOM_COMMAND_SUBTEXT"),
                    on_change=self._handle_custom_command_change
                ),
                Divider(),
                Header(text="Model"),
                Selector(
                    key="model_selection",
                    text=locali.get_string("MODEL_SELECTOR"),
                    icon="msg_media",
                    default=0,
                    items=MODEL_DISPLAY_NAMES
                ),
                Divider(),
                Header(text=locali.get_string("ROLES_HEADER")),
                Selector(
                    key="role_selection",
                    text=locali.get_string("ROLE_SELECTOR"),
                    icon="camera_revert1",
                    default=0,
                    items=role_names,
                    on_change=self._handle_role_selection_change
                ),
                Input(
                    key="custom_prompt",
                    text=locali.get_string("CUSTOM_PROMPT_INPUT"),
                    icon="filled_unknown",
                    default="",
                    subtext="–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Ä–æ–ª–∏. –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ò–ò.",
                    on_change=self._handle_custom_prompt_change
                ),
                Divider(),
                Header(text=locali.get_string("GENERATION_HEADER")),
                Input(
                    key="gemini_temperature",
                    text=locali.get_string("TEMPERATURE_INPUT"),
                    icon="msg_photo_settings",
                    default="0.7",
                    subtext=locali.get_string("TEMPERATURE_SUBTEXT")
                ),
                Input(
                    key="gemini_max_tokens",
                    text=locali.get_string("MAX_TOKENS_INPUT"),
                    icon="msg_photo_settings",
                    default="4096",
                    subtext=locali.get_string("MAX_TOKENS_SUBTEXT")
                ),
                Divider(),
                Header(text=locali.get_string("APPEARANCE_HEADER")),
                Switch(
                    key="use_markdown",
                    text=locali.get_string("USE_MARKDOWN_TITLE"),
                    subtext=locali.get_string("USE_MARKDOWN_SUBTEXT"),
                    icon="ic_masks_msk1",
                    default=False
                ),
                Switch(
                    key="use_blockquote",
                    text=locali.get_string("USE_BLOCKQUOTE_TITLE"),
                    subtext=locali.get_string("USE_BLOCKQUOTE_SUBTEXT"),
                    icon="ic_outinline",
                    default=True
                ),
                Switch(
                    key="use_premium_emoji",
                    text=locali.get_string("USE_PREMIUM_EMOJI_TITLE"),
                    subtext=locali.get_string("USE_PREMIUM_EMOJI_SUBTEXT"),
                    icon="menu_feature_reactions_remix",
                    default=False
                ),
                Switch(
                    key="show_request_response_format",
                    text="–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ",
                    subtext="–û—Ç–æ–±—Ä–∞–∂–∞—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å —Å–∏–º–≤–æ–ª–æ–º ‚ú¶ –∏ –æ—Ç–≤–µ—Ç –ò–ò —Å —Å–∏–º–≤–æ–ª–æ–º ü§ñ",
                    icon="msg_viewreplies",
                    default=True
                ),
                Divider(),
                Header(text=locali.get_string("CONTEXT_HEADER")),
                Switch(
                    key="context_enabled",
                    text=locali.get_string("CONTEXT_ENABLED_TITLE"),
                    subtext=locali.get_string("CONTEXT_ENABLED_SUBTEXT"),
                    icon="menu_username_set",
                    default=True
                ),
                Input(
                    key="context_length",
                    text=locali.get_string("CONTEXT_LENGTH_INPUT"),
                    icon="msg_photo_settings",
                    default="5",
                    subtext=locali.get_string("CONTEXT_LENGTH_SUBTEXT"),
                    on_change=self._handle_context_length_change
                ),
                Text(
                    text=locali.get_string("CLEAR_ALL_CONTEXT_TITLE"),
                    icon="msg_delete",
                    red=True,
                    on_click=self._handle_clear_all_context_click
                ),
                Divider(),
                Header(text=locali.get_string("ZWYLIB_HEADER")),
                Text(
                    text=locali.get_string("ZWYLIB_STATUS_TITLE") + ": " + ("‚úÖ" if is_zwylib_present() else "‚ùå"),
                    icon="menu_factcheck" if is_zwylib_present() else "msg_cancel",
                    accent=is_zwylib_present()
                ),
                Switch(
                    key="enable_autoupdate",
                    text=locali.get_string("AUTOUPDATE_TITLE") + (" (–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ)" if not is_zwylib_present() else ""),
                    subtext=locali.get_string("AUTOUPDATE_SUBTEXT"),
                    icon="msg_channel_create",
                    default=True if is_zwylib_present() else False,
                    on_change=self._toggle_autoupdate if is_zwylib_present() else None
                ),
                Switch(
                    key="use_zwylib_cache",
                    text=locali.get_string("ZWYLIB_CACHE_TITLE") + (" (–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ)" if not is_zwylib_present() else ""),
                    subtext=locali.get_string("ZWYLIB_CACHE_SUBTEXT"),
                    icon="msg_contacts_time",
                    default=True if is_zwylib_present() else False,
                    on_change=self._handle_cache_toggle if is_zwylib_present() else None
                ),
                Divider(),
                Header(text="–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏"),
                Switch(
                    key="enable_vision",
                    text="–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
                    subtext="–í–∫–ª—é—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥—É .img",
                    icon="files_gallery",
                    default=True
                ),
                Selector(
                    key="vision_style",
                    text="–°—Ç–∏–ª—å –∞–Ω–∞–ª–∏–∑–∞",
                    items=["–ö—Ä–∞—Ç–∫–∏–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π", "–ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑"],
                    default=0,
                    icon="msg_photo_settings"
                ),
                Divider(text="–ö—Ä–∞—Ç–∫–∏–π —Å—Ç–∏–ª—å –¥–∞–µ—Ç —Å–∂–∞—Ç—ã–µ –æ—Ç–≤–µ—Ç—ã, –ø–æ–¥—Ä–æ–±–Ω—ã–π - –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"),
                Divider(),
                Header(text="–ê—É–¥–∏–æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞"),
                Switch(
                    key="enable_audio",
                    text="–í–∫–ª—é—á–∏—Ç—å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –∞—É–¥–∏–æ",
                    subtext="–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥—É .audio",
                    icon="msg_allowspeak_solar",
                    default=True
                ),

                Divider(),
                Switch(
                    key="track_tokens",
                    text="–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤",
                    subtext="–í–µ–¥–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤",
                    icon="ic_ab_search",
                    default=True
                ),
                Text(
                    text="–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤",
                    icon="msg_stats",
                    accent=True,
                    on_click=self._handle_show_token_stats
                ),
                Divider(),
                Text(
                    text=locali.get_string("USAGE_INFO_TITLE"),
                    icon="msg_info",
                    on_click=self._handle_show_info_alert_click
                )
            ]
        except Exception:
            error_text = (
                f"An exception occurred in {self.__class__.__name__}.create_settings():\n\n"
                f"{traceback.format_exc().rstrip()}"
            )
            log(f"[AIAssistant] CREATE_SETTINGS_ERROR: {error_text}")
            return [Divider(text=error_text)]

    def _open_link(self, url: str):
        from android.content import Intent
        from android.net import Uri
        last_fragment = get_last_fragment()
        if not last_fragment: return
        context = last_fragment.getParentActivity()
        if not context: return
        intent = Intent(Intent.ACTION_VIEW, Uri.parse(url))
        context.startActivity(intent)

    def _show_error_bulletin(self, key: str, **kwargs):
        message = locali.get_string(key).format(**kwargs)
        message = get_regular_emoji_for_bulletin(message)
        run_on_ui_thread(lambda: BulletinHelper.show_error(message))

    def _show_bulletin_safe(self, bulletin_type: str, message: str):
        safe_message = get_regular_emoji_for_bulletin(message)
        if bulletin_type == "success":
            run_on_ui_thread(lambda: BulletinHelper.show_success(safe_message))
        elif bulletin_type == "error":
            run_on_ui_thread(lambda: BulletinHelper.show_error(safe_message))
        elif bulletin_type == "info":
            run_on_ui_thread(lambda: BulletinHelper.show_info(safe_message))

    def _handle_show_info_alert_click(self, view):
        title = locali.get_string("USAGE_INFO_TITLE")
        text = locali.get_string("USAGE_INFO_TEXT")
        close_button = locali.get_string("ALERT_CLOSE_BUTTON")
        parsed_text = parse_markdown(text)
        self.alert_manager.show_info_alert(title, parsed_text.text, close_button)

    def _get_formatted_token_stats(self) -> str:
        try:
            if not self.token_usage_manager:
                return "‚ùå –ú–µ–Ω–µ–¥–∂–µ—Ä —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"

            total = self.token_usage_manager.usage_data.get("total_tokens", 0)
            current_date = time.strftime("%Y-%m-%d")
            current_month = time.strftime("%Y-%m")
            daily = self.token_usage_manager.usage_data.get("daily_usage", {}).get(current_date, 0)
            monthly = self.token_usage_manager.usage_data.get("monthly_usage", {}).get(current_month, 0)
            sessions_count = len(self.token_usage_manager.usage_data.get("sessions", []))

            stats_text = (
                f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤**\n\n"
                f"üî¢ **–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤:** {total:,}\n"
                f"üìÖ **–°–µ–≥–æ–¥–Ω—è:** {daily:,}\n"
                f"üìÜ **–í —ç—Ç–æ–º –º–µ—Å—è—Ü–µ:** {monthly:,}\n"
                f"üí¨ **–°–µ—Å—Å–∏–π:** {sessions_count}\n\n"
                f"üí° *–¢–æ–∫–µ–Ω—ã —É—á–∏—Ç—ã–≤–∞—é—Ç –≤—Ö–æ–¥—è—â–∏–π –∏ –∏—Å—Ö–æ–¥—è—â–∏–π —Ç–µ–∫—Å—Ç*"
            )

            return stats_text
        except Exception as e:
            log(f"[AIAssistant] Error getting formatted token stats: {e}")
            return "‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"

    def _handle_show_token_stats(self, view):
        try:
            stats_text = self._get_formatted_token_stats()
            parsed_stats = parse_markdown(stats_text)
            self.alert_manager.show_info_alert("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤", parsed_stats.text, "–ó–∞–∫—Ä—ã—Ç—å")
        except Exception as e:
            log(f"[AIAssistant] Error showing token stats: {e}")
            run_on_ui_thread(lambda: BulletinHelper.show_error("–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"))

    def _handle_clear_all_context_click(self, view):
        self._clear_all_contexts()
        run_on_ui_thread(lambda: BulletinHelper.show_success(locali.get_string("CONTEXT_CLEARED")))

    def _handle_context_length_change(self, new_value: str):
        try:
            length = int(new_value)
            if length < 1 or length > 20:
                run_on_ui_thread(lambda: BulletinHelper.show_error("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç 1 –¥–æ 20"))
                return
        except (ValueError, TypeError):
            run_on_ui_thread(lambda: BulletinHelper.show_error("–í–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ"))

    def _handle_role_selection_change(self, new_role_index: int):
        user_selectable_roles = ["assistant", "universal", "creative", "translator", "programmer", "writer", "teacher", "analyst", "custom"]
        is_custom_role = new_role_index == len(user_selectable_roles) - 1

        if is_custom_role:
            custom_prompt = self.get_setting("custom_prompt", "")
            if custom_prompt and custom_prompt.strip():
                log(f"[AIAssistant] Custom role selected with existing prompt: {custom_prompt[:50]}...")
                run_on_ui_thread(lambda: BulletinHelper.show_info("üé≠ –í—ã–±—Ä–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ä–æ–ª—å. –ê–∫—Ç–∏–≤–µ–Ω –≤–∞—à —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç"))
            else:
                log("[AIAssistant] Custom role selected but no prompt set")
                run_on_ui_thread(lambda: BulletinHelper.show_info("üé≠ –í—ã–±—Ä–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ä–æ–ª—å. ‚ö†Ô∏è –£–∫–∞–∂–∏—Ç–µ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∏–∂–µ"))
        else:
            role_names_ru = ["–ü–æ–º–æ—â–Ω–∏–∫", "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π", "–ö—Ä–µ–∞—Ç–∏–≤–Ω—ã–π", "–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫", "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç", "–ü–∏—Å–∞—Ç–µ–ª—å", "–£—á–∏—Ç–µ–ª—å", "–ê–Ω–∞–ª–∏—Ç–∏–∫"]
            role_names_en = ["Assistant", "Universal", "Creative", "Translator", "Programmer", "Writer", "Teacher", "Analyst"]
            role_names = role_names_ru if locali.language == "ru" else role_names_en

            if 0 <= new_role_index < len(role_names):
                role_name = role_names[new_role_index]
                selected_role_key = user_selectable_roles[new_role_index]
                log(f"[AIAssistant] Role changed to: {selected_role_key}")
                run_on_ui_thread(lambda: BulletinHelper.show_info(f"üé≠ –í—ã–±—Ä–∞–Ω–∞ —Ä–æ–ª—å: {role_name}"))

    def _handle_custom_prompt_change(self, new_value: str):
        role_index = self.get_setting("role_selection", 0)
        try:
            role_index = int(role_index)
        except (ValueError, TypeError):
            role_index = 0
        user_selectable_roles = ["assistant", "universal", "creative", "translator", "programmer", "writer", "teacher", "analyst", "custom"]
        is_custom_role_selected = role_index == len(user_selectable_roles) - 1

        if new_value.strip():
            log(f"[AIAssistant] Custom prompt updated: {new_value[:50]}...")
            if is_custom_role_selected:
                run_on_ui_thread(lambda: BulletinHelper.show_info("‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –∞–∫—Ç–∏–≤–µ–Ω"))
            else:
                run_on_ui_thread(lambda: BulletinHelper.show_info("üíæ –ü—Ä–æ–º–ø—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω. –í—ã–±–µ—Ä–∏—Ç–µ '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ä–æ–ª—å' –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏"))
        else:
            log("[AIAssistant] Custom prompt cleared")
            if is_custom_role_selected:
                run_on_ui_thread(lambda: BulletinHelper.show_info("üîÑ –ü—Ä–æ–º–ø—Ç –æ—á–∏—â–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–æ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"))
            else:
                run_on_ui_thread(lambda: BulletinHelper.show_info("üóëÔ∏è –ü—Ä–æ–º–ø—Ç –æ—á–∏—â–µ–Ω"))

    def _handle_no_command_mode_change(self, new_value: bool):
        try:
            if new_value:
                run_on_ui_thread(lambda: BulletinHelper.show_info("üöÄ –†–µ–∂–∏–º –±–µ–∑ –∫–æ–º–∞–Ω–¥ –≤–∫–ª—é—á–µ–Ω! –¢–µ–ø–µ—Ä—å –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –ò–ò"))
                log("[AIAssistant] No command mode enabled")
            else:
                custom_command = self.get_setting("custom_command", ".ai")
                run_on_ui_thread(lambda: BulletinHelper.show_info(f"üéØ –†–µ–∂–∏–º –∫–æ–º–∞–Ω–¥ –≤–∫–ª—é—á–µ–Ω! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ {custom_command} –¥–ª—è –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –ò–ò"))
                log("[AIAssistant] Command mode enabled")
        except Exception as e:
            log(f"[AIAssistant] Error in no command mode change: {str(e)}")

    def _handle_custom_command_change(self, new_value: str):
        try:
            command = new_value.strip()
            if not command:
                command = ".ai"
                self.set_setting("custom_command", command)
                run_on_ui_thread(lambda: BulletinHelper.show_info("–ö–æ–º–∞–Ω–¥–∞ —Å–±—Ä–æ—à–µ–Ω–∞ –Ω–∞ .ai"))
                return
            if not command.startswith('.'):
                command = '.' + command
                self.set_setting("custom_command", command)
            if not all(c.isalnum() or c in '._-' for c in command[1:]):
                run_on_ui_thread(lambda: BulletinHelper.show_error("–ö–æ–º–∞–Ω–¥–∞ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã, —Ç–æ—á–∫–∏, –¥–µ—Ñ–∏—Å—ã –∏ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è"))
                return
            no_command_mode = self.get_setting("no_command_mode", False)
            if not no_command_mode:
                run_on_ui_thread(lambda: BulletinHelper.show_info(f"‚úÖ –ö–æ–º–∞–Ω–¥–∞ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {command}"))
            else:
                run_on_ui_thread(lambda: BulletinHelper.show_info(f"‚úÖ –ö–æ–º–∞–Ω–¥–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {command} (–∞–∫—Ç–∏–≤–Ω–∞ –ø—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–∏ —Ä–µ–∂–∏–º–∞ –±–µ–∑ –∫–æ–º–∞–Ω–¥)"))
        except Exception as e:
            log(f"[AIAssistant] Error in custom command change: {str(e)}")
            run_on_ui_thread(lambda: BulletinHelper.show_error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–º–∞–Ω–¥—ã"))

    def _handle_quick_role_change(self, context):
        try:
            current_role = self.get_setting("role_selection", 0)
            try:
                current_role = int(current_role)
            except (ValueError, TypeError):
                current_role = 0
            role_names_ru = ["–ü–æ–º–æ—â–Ω–∏–∫", "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π", "–ö—Ä–µ–∞—Ç–∏–≤–Ω—ã–π", "–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫", "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç", "–ü–∏—Å–∞—Ç–µ–ª—å", "–£—á–∏—Ç–µ–ª—å", "–ê–Ω–∞–ª–∏—Ç–∏–∫", "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ä–æ–ª—å"]
            next_role = (current_role + 1) % len(role_names_ru)
            self.set_setting("role_selection", next_role)
            role_name = role_names_ru[next_role]
            if next_role == len(role_names_ru) - 1:
                custom_prompt = self.get_setting("custom_prompt", "")
                if custom_prompt and custom_prompt.strip():
                    message = f"üé≠ –†–æ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {role_name}"
                    log(f"[AIAssistant] Quick role change to custom with prompt: {custom_prompt[:50]}...")
                else:
                    message = f"üé≠ –†–æ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {role_name}\n‚ö†Ô∏è –£–∫–∞–∂–∏—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö!"
                    log("[AIAssistant] Quick role change to custom but no prompt set")
            else:
                message = f"üé≠ –†–æ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {role_name}"
                user_selectable_roles = ["assistant", "universal", "creative", "translator", "programmer", "writer", "teacher", "analyst", "custom"]
                log(f"[AIAssistant] Quick role change to: {user_selectable_roles[next_role]}")
            run_on_ui_thread(lambda: BulletinHelper.show_success(message))
        except Exception as e:
            log(f"[AIAssistant] Error in quick role change: {str(e)}")
            run_on_ui_thread(lambda: BulletinHelper.show_error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–º–µ–Ω–µ —Ä–æ–ª–∏"))

    def _handle_quick_context_toggle(self, context):
        try:
            current_enabled = self.get_setting("context_enabled", True)
            new_enabled = not current_enabled
            self.set_setting("context_enabled", new_enabled)
            if new_enabled:
                message = "üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –≤–∫–ª—é—á–µ–Ω"
            else:
                message = "üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –æ—Ç–∫–ª—é—á–µ–Ω"
            run_on_ui_thread(lambda: BulletinHelper.show_success(message))
        except Exception as e:
            log(f"[AIAssistant] Error in context toggle: {str(e)}")
            run_on_ui_thread(lambda: BulletinHelper.show_error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"))

    def _handle_quick_context_clear(self, context):
        log("[AIAssistant] _handle_quick_context_clear function called!")
        try:
            self._clear_all_contexts()
            message_text = "üßπ –í—Å–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –æ—á–∏—â–µ–Ω—ã!"
            log("[AIAssistant] All contexts cleared successfully")
            run_on_ui_thread(lambda: BulletinHelper.show_success(message_text))
        except Exception as e:
            log(f"[AIAssistant] Error in _handle_quick_context_clear: {str(e)}")
            log(f"[AIAssistant] Full traceback: {traceback.format_exc()}")
            run_on_ui_thread(lambda: BulletinHelper.show_error(f"–û—à–∏–±–∫–∞: {str(e)}"))

    def _handle_quick_ai_toggle(self, context):
        try:
            current_enabled = self.get_setting("enabled", True)
            new_enabled = not current_enabled
            self.set_setting("enabled", new_enabled)
            if new_enabled:
                message = "ü§ñ AI Assistant –≤–∫–ª—é—á–µ–Ω"
                log("[AIAssistant] AI Assistant enabled via quick toggle")
            else:
                message = "ü§ñ AI Assistant –≤—ã–∫–ª—é—á–µ–Ω"
                log("[AIAssistant] AI Assistant disabled via quick toggle")
            self._show_bulletin_safe("success", message)
        except Exception as e:
            log(f"[AIAssistant] Error in quick AI toggle: {str(e)}")
            run_on_ui_thread(lambda: BulletinHelper.show_error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–∏ AI"))

    def _get_commands_list(self) -> List[str]:
        no_command_mode = self.get_setting("no_command_mode", False)
        if no_command_mode:
            return []
        custom_command = self.get_setting("custom_command", ".ai").strip()
        commands = []
        if custom_command and custom_command != ".ai":
            commands.append(custom_command)
        else:
            commands.extend(DEFAULT_COMMANDS)
        commands.extend(SPECIAL_COMMANDS)
        return commands

    def _get_role_prompt(self) -> str:
        role_index = self.get_setting("role_selection", 0)
        try:
            role_index = int(role_index)
        except (ValueError, TypeError):
            role_index = 0

        user_selectable_roles = ["assistant", "universal", "creative", "translator", "programmer", "writer", "teacher", "analyst", "custom"]

        if role_index == len(user_selectable_roles) - 1:
            custom_prompt = self.get_setting("custom_prompt", "")
            if custom_prompt and custom_prompt.strip():
                log(f"[AIAssistant] Using custom system prompt: {custom_prompt[:50]}...")
                return custom_prompt.strip()
            else:
                log("[AIAssistant] Custom role selected but no custom prompt set, using assistant role")
                return ROLE_PRESETS["assistant"]

        if 0 <= role_index < len(user_selectable_roles) - 1:
            selected_role = user_selectable_roles[role_index]
            log(f"[AIAssistant] Using predefined role: {selected_role}")
            return ROLE_PRESETS[selected_role]

        log("[AIAssistant] Invalid role index, using assistant role")
        return ROLE_PRESETS["assistant"]

    def _get_chat_context(self, chat_id: int) -> List[str]:
        if not self.get_setting("context_enabled", True):
            return []
        if self.context_cache_manager:
            return self.context_cache_manager.get_context(chat_id)
        return []

    def _add_to_context(self, chat_id: int, message: str, is_user: bool = True):
        if not self.get_setting("context_enabled", True) or not self.context_cache_manager:
            return
        max_context = self._get_context_length()
        current_context = self.context_cache_manager.get_context(chat_id)
        max_msg_length = 500
        if len(message) > max_msg_length:
            message = message[:max_msg_length] + "..."
        prefix = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: " if is_user else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: "
        current_context.append(prefix + message)
        if len(current_context) > max_context * 2:
            current_context = current_context[-max_context * 2:]
        self.context_cache_manager.set_context(chat_id, current_context)

    def _get_context_length(self) -> int:
        context_length = self.get_setting("context_length", "5")
        try:
            length = int(context_length)
            return max(1, min(20, length))
        except (ValueError, TypeError):
            return 5

    def _clear_chat_context(self, chat_id: int):
        if self.context_cache_manager:
            self.context_cache_manager.clear_context(chat_id)

    def _clear_all_contexts(self):
        if self.context_cache_manager:
            self.context_cache_manager.clear_all_contexts()

    def _detect_special_commands(self, message: str) -> tuple:
        message_lower = message.lower().strip()
        if message_lower.startswith(".tokens") or message_lower.startswith(".stats"):
            return ("tokens", message)
        elif message_lower.startswith(".img"):
            return ("img", message)
        elif message_lower.startswith(".audio"):
            return ("audio", message)
        return ("normal", message)





    def _build_system_and_user_prompts(self, user_message: str, chat_id: int, replied_message: str = None, media_data: str = None, is_img_command: bool = False, is_audio_command: bool = False, audio_type: str = None) -> tuple:
        if is_img_command:
            vision_style = self.get_setting("vision_style", 0)
            if vision_style == 1:
                system_prompt = ROLE_PRESETS["vision_detailed"]
                log("[AIAssistant] Using detailed vision role for .img command")
            else:
                system_prompt = ROLE_PRESETS["vision"]
                log("[AIAssistant] Using brief vision role for .img command")
        elif is_audio_command:
            system_prompt = self._get_audio_prompt(audio_type or 'voice')
            log("[AIAssistant] Using audio transcription prompt")
        else:
            system_prompt = self._get_role_prompt()
            log("[AIAssistant] Retrieved system prompt for normal message processing")

        system_additions = []

        message_lower = user_message.lower()
        if any(word in message_lower for word in ["–ø–µ—Ä–µ–≤–µ–¥–∏", "translate", "–ø–µ—Ä–µ–≤–æ–¥"]):
            system_additions.append("–û–±—Ä–∞—Ç–∏ –æ—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–º—ã—Å–ª–∞.")
        elif any(word in message_lower for word in ["–∫–æ–¥", "code", "–ø—Ä–æ–≥—Ä–∞–º–º", "script", "function"]):
            system_additions.append("–ü—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –∫–æ–¥–æ–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π —á–µ—Ç–∫–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –∏ –ø—Ä–∏–º–µ—Ä—ã.")
        elif any(word in message_lower for word in ["–æ–±—ä—è—Å–Ω–∏", "explain", "—á—Ç–æ —Ç–∞–∫–æ–µ", "–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç"]):
            system_additions.append("–î–∞–≤–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–µ, –Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏.")
        elif any(word in message_lower for word in ["–ø–æ–º–æ–≥–∏", "help", "–∫–∞–∫", "how"]):
            system_additions.append("–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã –∏ –ø–æ—à–∞–≥–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.")

        if media_data:
            if media_data.startswith("IMAGE_DATA:"):
                vision_style = self.get_setting("vision_style", 0)
                if vision_style == 1:
                    system_additions.append("–¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ä–æ–±–Ω—ã–º –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ —Ç–æ–≥–æ, —á—Ç–æ –≤–∏–¥–∏—à—å.")
                else:
                    system_additions.append("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É. –û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º, –ø–æ–Ω—è—Ç–Ω—ã–º –æ–±—ã—á–Ω–æ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.")
            elif media_data.startswith("AUDIO_DATA:"):
                system_additions.append("–¢—ã —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ—à—å –∞—É–¥–∏–æ. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Ç–æ—á–Ω—É—é —Ç–µ–∫—Å—Ç–æ–≤—É—é —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∞—É–¥–∏–æ.")
        use_blockquote = self.get_setting("use_blockquote", False)
        if use_blockquote:
            system_additions.append("–í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º –ë–ï–ó –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è markdown-—Ä–∞–∑–º–µ—Ç–∫–∏. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–∏–º–≤–æ–ª—ã **, __, `, ~, ||, [] –∏ –¥—Ä—É–≥–∏–µ —Å–∏–º–≤–æ–ª—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –ü–∏—à–∏ –ø—Ä–æ—Å—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º.")
        else:
            use_markdown = self.get_setting("use_markdown", True)
            if use_markdown:
                system_additions.append("–ú–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å markdown-—Ä–∞–∑–º–µ—Ç–∫—É –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞: **–∂–∏—Ä–Ω—ã–π**, *–∫—É—Ä—Å–∏–≤*, `–∫–æ–¥`, ```–±–ª–æ–∫ –∫–æ–¥–∞```.")
        system_additions.append("–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –∏–ª–∏ –Ω–∞ —Ç–æ–º —è–∑—ã–∫–µ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –∑–∞–¥–∞–Ω –≤–æ–ø—Ä–æ—Å.")

        if system_additions:
            final_system_prompt = system_prompt + "\n\n" + "\n".join(system_additions)
            log(f"[AIAssistant] Final system prompt length: {len(final_system_prompt)} characters")
        else:
            final_system_prompt = system_prompt
            log(f"[AIAssistant] Using base system prompt, length: {len(final_system_prompt)} characters")

        system_prompt = final_system_prompt
        user_parts = []
        context = self._get_chat_context(chat_id)
        if context:
            user_parts.append("–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π:")
            user_parts.extend(context)
            user_parts.append("")
        if replied_message:
            user_parts.append(f"–°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {replied_message}")
            user_parts.append("")
        if media_data:
            if media_data.startswith("IMAGE_DATA:"):
                vision_style = self.get_setting("vision_style", 0)
                if vision_style == 1:
                    user_parts.append("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
                else:
                    user_parts.append("–ü–æ—Å–º–æ—Ç—Ä–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –∫—Ä–∞—Ç–∫–æ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.")
            elif media_data.startswith("AUDIO_DATA:"):
                user_parts.append("–†–∞—Å—à–∏—Ñ—Ä—É–π –∞—É–¥–∏–æ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
            user_parts.append("")
        user_parts.append(f"–í–æ–ø—Ä–æ—Å: {user_message}")
        user_prompt = "\n".join(user_parts)
        return system_prompt, user_prompt

    def _prepare_message_params(self, params: Any) -> Any:
        try:
            message_params = type('MessageParams', (), {})()
            message_params.peer = params.peer
            if hasattr(params, 'replyToMsg') and params.replyToMsg:
                message_params.replyToMsg = params.replyToMsg
            else:
                message_params.replyToMsg = None
            if hasattr(params, 'replyToTopMsg') and params.replyToTopMsg:
                message_params.replyToTopMsg = params.replyToTopMsg
            else:
                message_params.replyToTopMsg = None
            return message_params
        except Exception as e:
            log(f"[AIAssistant] Error preparing message params: {e}")
            fallback_params = type('MessageParams', (), {})()
            fallback_params.peer = params.peer
            fallback_params.replyToMsg = None
            fallback_params.replyToTopMsg = None
            return fallback_params

    def _process_ai_request_in_background(self, params: Any, user_message: str, replied_message: str = None, media_data: str = None, is_img_command: bool = False, is_audio_command: bool = False, audio_type: str = None):
        try:
            api_key = self.get_setting("gemini_api_key", "")
            model_idx = self.get_setting("model_selection", 0)
            model_name = MODEL_API_NAMES[model_idx]
            temperature = float(self.get_setting("gemini_temperature", "0.7"))
            max_tokens = int(self.get_setting("gemini_max_tokens", "4096"))

            chat_id = self._get_chat_id_from_params(params)
            self._add_to_context(chat_id, user_message, is_user=True)
            system_prompt, user_prompt = self._build_system_and_user_prompts(user_message, chat_id, replied_message, media_data, is_img_command, is_audio_command, audio_type)

            if not system_prompt or not system_prompt.strip():
                log("[AIAssistant] Warning: Empty system prompt detected, using default assistant role")
                system_prompt = ROLE_PRESETS["assistant"]
            audio_data = media_data if is_audio_command else None
            image_data = media_data if is_img_command else None
            result = self.api_handler.send_request(api_key, model_name, user_prompt, temperature, max_tokens, image_data, audio_data, system_prompt)

            if result.get("success"):
                response_text = result["text"]
                self._add_to_context(chat_id, response_text, is_user=False)
                if self.get_setting("track_tokens", True) and self.token_usage_manager:
                    input_tokens = result.get("input_tokens", 0)
                    output_tokens = result.get("output_tokens", 0)
                    if input_tokens > 0 or output_tokens > 0:
                        self.token_usage_manager.add_usage(input_tokens, output_tokens, model_name)
                self._send_ai_response(params, response_text, user_message)
            else:
                self._show_error_bulletin("API_ERROR", error=result.get("error", "Unknown"))
        except Exception as e:
            self._show_error_bulletin("UNEXPECTED_ERROR", error=str(e))
            log(traceback.format_exc())

    def _send_ai_response(self, params: Any, response_text: str, user_message: str = None):
        use_markdown = self.get_setting("use_markdown", True)
        use_blockquote = self.get_setting("use_blockquote", False)
        use_premium_emoji = self.get_setting("use_premium_emoji", False)
        show_request_response_format = self.get_setting("show_request_response_format", False)
        formatted_response = self._format_ai_response(response_text)
        if show_request_response_format and user_message:
            formatted_response = f"‚ú¶ {user_message}\n‚∏ª‚∏ª‚∏ª\nü§ñ {formatted_response}"
        elif not show_request_response_format:
            formatted_response = f"ü§ñ {formatted_response}"
        if use_premium_emoji:
            formatted_response = replace_with_premium_emoji(formatted_response)
        prepared_params = self._prepare_message_params(params)
        message_payload = {"peer": prepared_params.peer}
        if prepared_params.replyToMsg:
            message_payload["replyToMsg"] = prepared_params.replyToMsg
        if prepared_params.replyToTopMsg:
            message_payload["replyToTopMsg"] = prepared_params.replyToTopMsg

        try:
            if use_blockquote:
                parsed = parse_markdown(formatted_response)
                entities = []
                if parsed.entities:
                    for entity in parsed.entities:
                        try:
                            tlrpc_entity = entity.to_tlrpc_object()
                            if tlrpc_entity is not None:
                                entities.append(tlrpc_entity)
                        except Exception as e:
                            log(f"[AIAssistant] Entity error: {e}")
                blockquote_entity = TLRPC.TL_messageEntityBlockquote()
                blockquote_entity.collapsed = True
                blockquote_entity.offset = 0
                blockquote_entity.length = len(parsed.text.encode('utf-16le')) // 2
                entities.append(blockquote_entity)
                message_payload["message"] = parsed.text
                message_payload["entities"] = entities if entities else None
            elif use_markdown:
                parsed = parse_markdown(formatted_response)
                message_payload["message"] = parsed.text
                message_payload["entities"] = [entity.to_tlrpc_object() for entity in parsed.entities] if parsed.entities else None
            else:
                message_payload["message"] = formatted_response
                message_payload["entities"] = None
            send_message(message_payload)
        except Exception:
            fallback_text = formatted_response.replace('**', '').replace('__', '').replace('`', '')
            message_payload["message"] = fallback_text
            message_payload["entities"] = None
            send_message(message_payload)

    def _send_formatted_message(self, params: Any, message_text: str, force_markdown: bool = False):
        use_markdown = self.get_setting("use_markdown", True) or force_markdown
        use_blockquote = self.get_setting("use_blockquote", False) and not force_markdown
        use_premium_emoji = self.get_setting("use_premium_emoji", False)
        if use_premium_emoji:
            message_text = replace_with_premium_emoji(message_text)
        prepared_params = self._prepare_message_params(params)
        message_payload = {"peer": prepared_params.peer}
        if prepared_params.replyToMsg:
            message_payload["replyToMsg"] = prepared_params.replyToMsg
        if prepared_params.replyToTopMsg:
            message_payload["replyToTopMsg"] = prepared_params.replyToTopMsg

        try:
            if use_blockquote:
                parsed = parse_markdown(message_text)
                entities = []
                if parsed.entities:
                    for entity in parsed.entities:
                        try:
                            tlrpc_entity = entity.to_tlrpc_object()
                            if tlrpc_entity is not None:
                                entities.append(tlrpc_entity)
                        except Exception as e:
                            log(f"[AIAssistant] Entity error: {e}")
                blockquote_entity = TLRPC.TL_messageEntityBlockquote()
                blockquote_entity.collapsed = True
                blockquote_entity.offset = 0
                blockquote_entity.length = len(parsed.text.encode('utf-16le')) // 2
                entities.append(blockquote_entity)
                message_payload["message"] = parsed.text
                message_payload["entities"] = entities if entities else None
            elif use_markdown:
                parsed = parse_markdown(message_text)
                message_payload["message"] = parsed.text
                message_payload["entities"] = [entity.to_tlrpc_object() for entity in parsed.entities] if parsed.entities else None
            else:
                message_payload["message"] = message_text
                message_payload["entities"] = None
            send_message(message_payload)
        except Exception:
            fallback_text = message_text.replace('**', '').replace('__', '').replace('`', '')
            message_payload["message"] = fallback_text
            message_payload["entities"] = None
            send_message(message_payload)

    def _format_ai_response(self, response_text: str) -> str:
        formatted = response_text.strip()
        max_length = 4000
        if len(formatted) > max_length:
            formatted = formatted[:max_length-3] + "..."
        return formatted

    def _get_chat_id_from_params(self, params: Any) -> int:
        peer = getattr(params, 'peer', None)
        if not peer:
            return 0
        if hasattr(peer, 'channel_id') and peer.channel_id != 0:
            return -peer.channel_id
        if hasattr(peer, 'chat_id') and peer.chat_id != 0:
            return -peer.chat_id
        if hasattr(peer, 'user_id') and peer.user_id != 0:
            return peer.user_id
        return 0

    def on_send_message_hook(self, account: int, params: Any) -> HookResult:
        if not hasattr(params, "message") or not isinstance(params.message, str):
            return HookResult()

        message_text = params.message.strip()
        if not message_text or not self.get_setting("enabled", True):
            return HookResult()
        import time
        current_time = time.time()
        if (self.last_processed_message == message_text and
            current_time - self.last_processed_time < 2):
            return HookResult()
        self.last_processed_message = message_text
        self.last_processed_time = current_time
        system_messages = [
            "üßπ –ö–æ–Ω—Ç–µ–∫—Å—Ç", "üé≠ –†–æ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞", "üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞",
            "üöÄ –†–µ–∂–∏–º –±–µ–∑ –∫–æ–º–∞–Ω–¥", "üéØ –†–µ–∂–∏–º –∫–æ–º–∞–Ω–¥", "‚úÖ –ö–æ–º–∞–Ω–¥–∞ –∏–∑–º–µ–Ω–µ–Ω–∞",
            "‚ö†Ô∏è –û—à–∏–±–∫–∞ API", "‚ùó –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞", "‚ùå API –∫–ª—é—á",
            "ü§ñ AI Assistant –≤–∫–ª—é—á–µ–Ω", "ü§ñ AI Assistant –≤—ã–∫–ª—é—á–µ–Ω",
            "üéôÔ∏è **–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è:**", "üéµ **–ê–Ω–∞–ª–∏–∑ –º—É–∑—ã–∫–∏:**"
        ]
        if any(msg in message_text for msg in system_messages):
            return HookResult()

        no_command_mode = self.get_setting("no_command_mode", False)
        if no_command_mode:
            if len(message_text.strip()) < 2:
                return HookResult()
            ai_response_patterns = [
                "–ö–æ–Ω–µ—á–Ω–æ!", "–†–∞–∑—É–º–µ–µ—Ç—Å—è!", "–•–æ—Ä–æ—à–æ!", "–ü–æ–Ω—è—Ç–Ω–æ!", "–Ø—Å–Ω–æ!",
                "–í–æ—Ç", "–≠—Ç–æ", "–î–∞,", "–ù–µ—Ç,", "–ú–æ–∂–µ—Ç –±—ã—Ç—å", "–í–æ–∑–º–æ–∂–Ω–æ"
            ]
            if len(message_text) > 50 and any(message_text.startswith(pattern) for pattern in ai_response_patterns):
                return HookResult()
        commands = self._get_commands_list()
        if no_command_mode:
            matching_command = ""
        else:
            matching_command = None
            for command in commands:
                if message_text.lower().startswith(command.lower()):
                    matching_command = command
                    break
            if not matching_command:
                return HookResult()

        api_key = self.get_setting("gemini_api_key", "")
        if not api_key:
            self._show_error_bulletin("API_KEY_MISSING")
            return HookResult(strategy=HookStrategy.CANCEL)
        is_img_command = False
        is_audio_command = False
        audio_type = None
        if not no_command_mode and matching_command:
            command_type, _ = self._detect_special_commands(matching_command)
            if command_type == "tokens":
                stats_text = self._get_formatted_token_stats()
                self._send_formatted_message(params, stats_text, force_markdown=True)
                return HookResult(strategy=HookStrategy.CANCEL)
            elif command_type == "img":
                if not (hasattr(params, 'replyToMsg') and params.replyToMsg):
                    params.message = "‚ùå –ö–æ–º–∞–Ω–¥–∞ .img —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—Ç–≤–µ—Ç–µ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º"
                    return HookResult(strategy=HookStrategy.MODIFY, params=params)
                reply_msg = params.replyToMsg.messageOwner
                if not (hasattr(reply_msg, 'media') and reply_msg.media):
                    params.message = "‚ùå –í —Å–æ–æ–±—â–µ–Ω–∏–∏, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–µ –≤—ã –æ—Ç–≤–µ—á–∞–µ—Ç–µ, –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
                    return HookResult(strategy=HookStrategy.MODIFY, params=params)
                if not (hasattr(reply_msg.media, 'photo') and reply_msg.media.photo):
                    params.message = "‚ùå –ö–æ–º–∞–Ω–¥–∞ .img —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏"
                    return HookResult(strategy=HookStrategy.MODIFY, params=params)
                is_img_command = True
                log("[AIAssistant] .img command detected with valid image reply")
            elif command_type == "audio":
                if not (hasattr(params, 'replyToMsg') and params.replyToMsg):
                    params.message = "‚ùå –ö–æ–º–∞–Ω–¥–∞ .audio —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—Ç–≤–µ—Ç–µ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∞—É–¥–∏–æ"
                    return HookResult(strategy=HookStrategy.MODIFY, params=params)
                reply_msg = params.replyToMsg
                if not self._is_supported_audio_message(reply_msg):
                    params.message = "‚ùå –í —Å–æ–æ–±—â–µ–Ω–∏–∏, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–µ –≤—ã –æ—Ç–≤–µ—á–∞–µ—Ç–µ, –Ω–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–≥–æ –∞—É–¥–∏–æ"
                    return HookResult(strategy=HookStrategy.MODIFY, params=params)
                is_audio_command = True
                audio_type = self._get_audio_type(reply_msg)

        if no_command_mode:
            user_message = message_text
        else:
            user_message = message_text[len(matching_command):].strip()
        media_data = None
        replied_message = None
        if hasattr(params, 'replyToMsg') and params.replyToMsg:
            reply_msg = params.replyToMsg.messageOwner
            if hasattr(reply_msg, 'message') and reply_msg.message:
                replied_message = reply_msg.message
            if hasattr(reply_msg, 'media') and reply_msg.media:
                if is_img_command:
                    media_data = self._extract_media_data(reply_msg.media, reply_msg)
                elif is_audio_command:
                    media_data = self._extract_audio_data(reply_msg)
        if not user_message and not replied_message and not media_data:
            user_message = "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?"
        BulletinHelper.show_info(locali.get_string("PROCESSING_MESSAGE"))
        run_on_queue(lambda: self._process_ai_request_in_background(params, user_message, replied_message, media_data, is_img_command, is_audio_command, audio_type))
        return HookResult(strategy=HookStrategy.CANCEL)

    def _extract_media_data(self, media: Any, message: Any) -> Optional[str]:
        try:
            if not self.get_setting("enable_vision", True):
                return None
            if hasattr(media, 'photo') and media.photo and self.get_setting("enable_vision", True):
                log("[AIAssistant] Found photo in media, extracting...")
                return self._extract_photo_data(media.photo, message)
            elif hasattr(media, 'document') and media.document:
                document = media.document
                mime_type = getattr(document, 'mime_type', '')
                if mime_type.startswith('image/') and self.get_setting("enable_vision", True):
                    return self._extract_document_image_data(document)
            return None
        except Exception as e:
            log(f"[AIAssistant] Error extracting media data: {e}")
            return None

    def _extract_audio_data(self, message: Any) -> Optional[str]:
        try:
            if not self._is_supported_audio_message(message):
                log("[AIAssistant] Message does not contain supported audio")
                return None
            msg_obj = None
            if hasattr(message, 'messageOwner'):
                msg_obj = message.messageOwner
            elif hasattr(message, 'media'):
                msg_obj = message
            else:
                log(f"[AIAssistant] Unknown message structure in extract_audio_data: {type(message)}")
                return None
            media = msg_obj.media
            document = None
            if hasattr(media, 'voice') and media.voice:
                document = media.voice
                log("[AIAssistant] Processing voice message")
            elif hasattr(media, 'round') and media.round:
                document = media.round
                log("[AIAssistant] Processing round video message")
            elif hasattr(media, 'document') and media.document:
                try:
                    document = MessageObject.getDocument(msg_obj)
                    if not document:
                        document = media.document
                    mime_type = getattr(document, 'mime_type', 'unknown')
                except Exception as e:
                    log(f"[AIAssistant] Error getting document via MessageObject.getDocument(): {e}")
                    document = media.document
                    mime_type = getattr(document, 'mime_type', 'unknown')
            if not document:
                return None
            audio_file_path = self._download_audio_file(document, message)
            if not audio_file_path:
                log("[AIAssistant] Failed to download audio file")
                return None
            audio_data = self._convert_audio_to_base64(audio_file_path)
            if not audio_data:
                return None
            return audio_data
        except Exception as e:
            log(f"[AIAssistant] Error extracting audio data: {e}")
            import traceback
            log(f"[AIAssistant] Traceback: {traceback.format_exc()}")
            return None



    def _extract_photo_data(self, photo: Any, message: Any = None) -> Optional[str]:
        try:
            if not hasattr(photo, 'sizes') or not photo.sizes:
                return "‚ùå –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞–∑–º–µ—Ä–æ–≤"

            file_loader = get_file_loader()
            if not file_loader:
                return "‚ùå FileLoader –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"

            if message:
                try:
                    file_path = file_loader.getPathToMessage(message)
                    if file_path and file_path.exists():
                        return self._convert_image_to_base64(file_path.getAbsolutePath())
                except Exception as e:
                    log(f"[AIAssistant] Error getting path from message: {e}")
            try:
                from org.telegram.messenger import FileLoader as TGFileLoader, ImageLocation
                best_size = TGFileLoader.getClosestPhotoSizeWithSize(photo.sizes, 1280, False, None, True)
                if not best_size:
                    best_size = photo.sizes[-1] if photo.sizes else None
                if best_size:
                    file_path = file_loader.getPathToAttach(best_size, None, False, True)
                    if file_path and file_path.exists():
                        return self._convert_image_to_base64(file_path.getAbsolutePath())
                    else:
                        image_location = ImageLocation.getForPhoto(best_size, photo)
                        if image_location:
                            file_loader.loadFile(image_location, message, "jpg", FileLoader.PRIORITY_HIGH, FileLoader.PRELOAD_CACHE_TYPE)
                            return "‚è≥ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥"
                        else:
                            return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å ImageLocation –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏"
            except Exception as e:
                log(f"[AIAssistant] Error with FileLoader methods: {e}")

            return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
        except Exception as e:
            log(f"[AIAssistant] Error extracting photo data: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"

    def _extract_document_image_data(self, document: Any) -> Optional[str]:
        try:
            file_loader = get_file_loader()
            if not file_loader:
                return "‚ùå FileLoader –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
            file_path = file_loader.getPathToAttach(document, None, False, True)
            if file_path and file_path.exists():
                return self._convert_image_to_base64(file_path.getAbsolutePath())
            else:
                file_loader.loadFile(document, None, FileLoader.PRIORITY_HIGH, FileLoader.PRELOAD_CACHE_TYPE)
                return "‚è≥ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥"
        except Exception as e:
            log(f"[AIAssistant] Error extracting document image data: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"

    def _convert_image_to_base64(self, file_path: str) -> Optional[str]:
        try:
            import os
            if not os.path.exists(file_path):
                log(f"[AIAssistant] Image file not found: {file_path}")
                return "‚ùå –§–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω"
            file_ext = os.path.splitext(file_path)[1].lower()
            mime_type_map = {
                '.jpg': 'image/jpeg',
                '.jpeg': 'image/jpeg',
                '.png': 'image/png',
                '.gif': 'image/gif',
                '.webp': 'image/webp',
                '.bmp': 'image/bmp'
            }
            mime_type = mime_type_map.get(file_ext, 'image/jpeg')
            with open(file_path, 'rb') as image_file:
                image_data = image_file.read()
                base64_data = base64.b64encode(image_data).decode('utf-8')
                return f"IMAGE_DATA:{mime_type}:{base64_data}"
        except Exception as e:
            log(f"[AIAssistant] Error converting image to base64: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"

    def _get_audio_type(self, message: Any) -> str:
        try:
            msg_obj = None
            if hasattr(message, 'messageOwner'):
                msg_obj = message.messageOwner
            elif hasattr(message, 'media'):
                msg_obj = message
            else:
                return 'none'
            if not msg_obj or not hasattr(msg_obj, 'media') or not msg_obj.media:
                return 'none'
            media = msg_obj.media
            if hasattr(media, 'voice') and media.voice:
                return 'voice'
            if hasattr(media, 'round') and media.round:
                return 'round'
            if hasattr(media, 'document') and media.document:
                document = media.document
                if hasattr(document, 'mime_type') and document.mime_type:
                    mime = str(document.mime_type).lower()
                    if mime.startswith('audio/'):
                        return 'music'
            return 'none'
        except Exception as e:
            log(f"[AIAssistant] Error determining audio type: {e}")
            return 'none'

    def _is_supported_audio_message(self, message: Any) -> bool:
        try:
            audio_type = self._get_audio_type(message)
            is_supported = audio_type in ['voice', 'round', 'music']
            return is_supported
        except Exception as e:
            log(f"[AIAssistant] Error checking audio message: {e}")
            return False

    def _get_audio_prompt(self, audio_type: str) -> str:
        if audio_type == 'music':
            return """–¢—ã - AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –º—É–∑—ã–∫–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º—É–∑—ã–∫–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–µ–¥—É—é—â–∏–º:

**–ê–Ω–∞–ª–∏–∑ –º—É–∑—ã–∫–∏:**

**–û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:**
- –ñ–∞–Ω—Ä: [–æ–ø—Ä–µ–¥–µ–ª–∏ –∂–∞–Ω—Ä –º—É–∑—ã–∫–∏]
- –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: [–æ–ø–∏—à–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É]
- –¢–µ–º–ø: [–º–µ–¥–ª–µ–Ω–Ω—ã–π/—Å—Ä–µ–¥–Ω–∏–π/–±—ã—Å—Ç—Ä—ã–π]
- –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: [–ø–µ—Ä–µ—á–∏—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã]

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏:**
- –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: [—É–∫–∞–∂–∏ –ø—Ä–∏–º–µ—Ä–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å]
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞: [–∫—É–ø–ª–µ—Ç/–ø—Ä–∏–ø–µ–≤/–±—Ä–∏–¥–∂ –∏ —Ç.–¥.]
- –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã: [–æ–ø–∏—à–∏ —è—Ä–∫–∏–µ —á–∞—Å—Ç–∏]

**–¢–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å):**
[—Ä–∞—Å—à–∏—Ñ—Ä—É–π —Ç–µ–∫—Å—Ç –ø–µ—Å–Ω–∏, –µ—Å–ª–∏ –æ–Ω –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç]

**–û–±—â–µ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ:**
[–¥–∞–π –∫—Ä–∞—Ç–∫—É—é –æ—Ü–µ–Ω–∫—É –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏, –µ—ë –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–æ]

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""
        elif audio_type in ['voice', 'round']:
            return """–¢—ã - AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Ç–æ—á–Ω–æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞—Ç—å —Ä–µ—á—å –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:

üéôÔ∏è **–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è:**

**–¢–µ–∫—Å—Ç:**
[—Ç–æ—á–Ω–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —Ä–µ—á–∏]

**–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:**
[–æ—Å–Ω–æ–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö]

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""
        else:
            return "–¢—ã - AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ –∏ –∞–Ω–∞–ª–∏–∑–µ –∞—É–¥–∏–æ. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Ç–æ—á–Ω–æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."

    def _find_existing_audio_file(self, file_path: str, document, message) -> Optional[str]:
        try:
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                if file_size > 0:
                    return file_path
            file_name = os.path.basename(file_path)
            base_dirs = [
                "/storage/emulated/0/Android/data/com.exteragram.messenger/files/exteraGram/exteraGram Documents",
                "/storage/emulated/0/Android/data/com.exteragram.messenger/files/exteraGram Documents",
                "/storage/emulated/0/Android/data/com.exteragram.messenger/files",
                "/storage/emulated/0/Android/data/com.exteragram.messenger/cache",
                "/storage/emulated/0/Telegram/Telegram Audio",
                "/storage/emulated/0/Telegram/Telegram Documents"
            ]
            for base_dir in base_dirs:
                alternative_path = os.path.join(base_dir, file_name)
                if os.path.exists(alternative_path):
                    file_size = os.path.getsize(alternative_path)
                    if file_size > 0:
                        return alternative_path
            return None
        except Exception as e:
            log(f"[AIAssistant] Error finding audio file: {e}")
            return None

    def _download_audio_file(self, document, message: Any) -> Optional[str]:
        try:
            if document is None:
                log("[AIAssistant] Document is None, cannot find audio file.")
                return None
            file_loader = get_file_loader()
            msg_obj = None
            if hasattr(message, 'messageOwner'):
                msg_obj = message.messageOwner
            elif hasattr(message, 'media'):
                msg_obj = message
            else:
                log(f"[AIAssistant] Unknown message structure in download_audio_file: {type(message)}")
                return None
            media = msg_obj.media
            is_voice_or_round = False
            if hasattr(media, 'voice') and media.voice:
                is_voice_or_round = True
                log("[AIAssistant] Detected voice message for download")
            elif hasattr(media, 'round') and media.round:
                is_voice_or_round = True
                log("[AIAssistant] Detected round video message for download")
            if is_voice_or_round:
                file_path_obj = file_loader.getPathToMessage(msg_obj)
            else:
                file_path_obj = file_loader.getPathToAttach(document, True)
            if file_path_obj is None:
                log("[AIAssistant] Get path returned null.")
                return None
            file_path = file_path_obj.getAbsolutePath()
            if not file_path:
                log("[AIAssistant] Audio file path is empty or null after getAbsolutePath.")
                return None
            found_path = self._find_existing_audio_file(file_path, document, message)
            if found_path:
                return found_path
            else:
                if not is_voice_or_round and document:
                    try:
                        if not file_path_obj:
                            log("[AIAssistant] file_path_obj is None, cannot download")
                            BulletinHelper.show_error("–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É")
                            return None
                        file_loader.loadFile(document, "music_transcription", FileLoader.PRIORITY_HIGH, 1)
                        import time
                        k = 0
                        while k < 40 and not file_path_obj.exists():
                            time.sleep(0.5)
                            k += 1
                        if file_path_obj.exists():
                            final_path = file_path_obj.getAbsolutePath()
                            return final_path
                        else:
                            found_path = self._find_existing_audio_file(file_path, document, message)
                            if found_path:
                                return found_path
                            else:
                                BulletinHelper.show_error("–ú—É–∑—ã–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.")
                                return None
                    except Exception as e:
                        log(f"[AIAssistant] Error initiating file download: {e}")
                        import traceback
                        log(f"[AIAssistant] Traceback: {traceback.format_exc()}")
                        BulletinHelper.show_error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º—É–∑—ã–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
                        return None
                else:
                    BulletinHelper.show_error("–ê—É–¥–∏–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    return None
        except Exception as e:
            log(f"[AIAssistant] Error finding audio file: {e}")
            import traceback
            log(f"[AIAssistant] Traceback: {traceback.format_exc()}")
            return None

    def _get_audio_mime_type(self, file_path: str) -> str:
        try:
            ext = os.path.splitext(file_path)[1].lower()
            mime_types = {
                '.ogg': 'audio/ogg',
                '.opus': 'audio/ogg',
                '.mp3': 'audio/mpeg',
                '.wav': 'audio/wav',
                '.m4a': 'audio/mp4',
                '.aac': 'audio/aac'
            }
            return mime_types.get(ext, 'audio/ogg')
        except Exception as e:
            log(f"[AIAssistant] Error determining audio MIME type: {e}")
            return 'audio/ogg'

    def _convert_audio_to_base64(self, file_path: str) -> Optional[str]:
        try:
            if not os.path.exists(file_path):
                log(f"[AIAssistant] Audio file not found: {file_path}")
                return None
            mime_type = self._get_audio_mime_type(file_path)
            with open(file_path, 'rb') as audio_file:
                audio_data = audio_file.read()
                base64_data = base64.b64encode(audio_data).decode('utf-8')
                return f"AUDIO_DATA:{mime_type}:{base64_data}"
        except Exception as e:
            log(f"[AIAssistant] Error converting audio to base64: {e}")
            return None

    def _is_audio_message_condition(self, message: Any) -> bool:
        try:
            if not self.get_setting("enable_audio", True):
                return False
            return self._is_supported_audio_message(message)
        except Exception as e:
            log(f"[AIAssistant] Error checking audio message condition: {e}")
            return False

    def _handle_audio_transcription(self, message: Any):
        try:
            if not self.get_setting("enable_audio", True):
                BulletinHelper.show_error("–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –∞—É–¥–∏–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")
                return
            if not self._is_supported_audio_message(message):
                BulletinHelper.show_error("–°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–≥–æ –∞—É–¥–∏–æ")
                return
            api_key = self.get_setting("gemini_api_key", "")
            if not api_key:
                BulletinHelper.show_error("API –∫–ª—é—á Gemini –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
                return
            BulletinHelper.show_info("–ù–∞—á–∏–Ω–∞—é —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –∞—É–¥–∏–æ...")
            run_on_queue(lambda: self._process_audio_transcription_background(message))
        except Exception as e:
            log(f"[AIAssistant] Error handling audio transcription: {e}")
            BulletinHelper.show_error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ –∞—É–¥–∏–æ: {str(e)}")

    def _process_audio_transcription_background(self, message: Any):
        try:
            audio_type = self._get_audio_type(message)
            audio_data = self._extract_audio_data(message)
            if not audio_data:
                run_on_ui_thread(lambda: BulletinHelper.show_error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—É–¥–∏–æ—Ñ–∞–π–ª"))
                return
            api_key = self.get_setting("gemini_api_key", "")
            model_idx = self.get_setting("model_selection", 0)
            model_name = MODEL_API_NAMES[model_idx]
            temperature = 0.1
            max_tokens = int(self.get_setting("gemini_max_tokens", "4096"))
            system_prompt = self._get_audio_prompt(audio_type)
            if audio_type == 'music':
                user_prompt = "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É –º—É–∑—ã–∫–∞–ª—å–Ω—É—é –∫–æ–º–ø–æ–∑–∏—Ü–∏—é:"
            else:
                user_prompt = "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞—Å—à–∏—Ñ—Ä—É–π —ç—Ç–æ –∞—É–¥–∏–æ —Å–æ–æ–±—â–µ–Ω–∏–µ:"
            result = self.api_handler.send_request(
                api_key, model_name, user_prompt, temperature, max_tokens,
                None, audio_data, system_prompt
            )
            if result.get("success"):
                response_text = result["text"]
                def send_transcription():
                    try:
                        chat_id = message.getDialogId()
                        if audio_type == 'music':
                            formatted_response = response_text
                        else:
                            if response_text.startswith("üéôÔ∏è **–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞"):
                                formatted_response = response_text
                            else:
                                formatted_response = f"üéôÔ∏è **–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è:**\n\n{response_text}"
                        reply_to_msg = None
                        if hasattr(message, 'messageOwner'):
                            reply_to_msg = message.messageOwner
                        else:
                            reply_to_msg = message
                        message_payload = {
                            "peer": chat_id,
                            "message": formatted_response,
                            "replyToMsg": reply_to_msg
                        }
                        send_message(message_payload)
                        BulletinHelper.show_success("–ê—É–¥–∏–æ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–æ!")
                    except Exception as e:
                        log(f"[AIAssistant] Error sending transcription: {e}")
                        BulletinHelper.show_error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏: {str(e)}")
                run_on_ui_thread(send_transcription)
            else:
                error_msg = result.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ API")
                run_on_ui_thread(lambda: BulletinHelper.show_error(f"–û—à–∏–±–∫–∞ API: {error_msg}"))
        except Exception as e:
            log(f"[AIAssistant] Error in background audio transcription: {e}")
            import traceback
            log(f"[AIAssistant] Traceback: {traceback.format_exc()}")
            run_on_ui_thread(lambda: BulletinHelper.show_error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏: {str(e)}"))

